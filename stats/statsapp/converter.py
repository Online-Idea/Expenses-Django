import ftplib
from ftplib import FTP
from functools import reduce
from pathlib import Path
import os

import pandas.core.series
import requests
import datetime
import xml.etree.ElementTree as ET
from openpyxl import Workbook
# import xlsxwriter
import pandas as pd
from pandas import DataFrame
from telebot.types import InputFile

from stats.settings import env
from statsapp.models import *
from statsapp.management.commands.bot import bot


# Ð¡Ð¿Ð¸ÑÐ¾Ðº ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¹: POST http://151.248.118.19/Api/Configurations/GetList
# Ð¡Ð¿Ð¸ÑÐ¾Ðº ÐŸÐ°Ð¿Ð¾Ðº Ñ Ñ„Ð¾Ñ‚Ð¾: POST http://151.248.118.19/Api/Stock/GetClients

# ÐŸÑ€Ð¾Ð³Ð¾Ð½ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð° (3 Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°)
# POST http://151.248.118.19/Api/Stock/StartProcess
# POST http://151.248.118.19/Api/Stock/GetProcessStep
# POST http://151.248.118.19/Api/Log/GetByProcessId

def get_converter_tasks():
    active_tasks = ConverterTask.objects.filter(active=True)
    return active_tasks


def get_price(task):
    """
    ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ Ñ†Ð¸ÐºÐ» Ð´Ð»Ñ Ð¾Ð´Ð½Ð¾Ð³Ð¾ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°.
    :param task: ÑÑ‚Ñ€Ð¾ÐºÐ° Ð¸Ð· Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ Ð—Ð°Ð´Ð°Ñ‡Ð¸ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚ÐµÑ€Ð°
    """
    template = converter_template(task)
    client_slug = task.client.slug
    client_name = task.client.name
    process_id = converter_post(task)
    price = converter_process_result(process_id, client_slug, template, task)
    logs = converter_logs(process_id)
    logs_xlsx = logs_to_xlsx(logs, template, client_slug)
    bot_messages(logs, logs_xlsx, price, client_slug, client_name)
    save_on_ftp(logs_xlsx)
    os.remove(logs_xlsx)
    print(f'ÐšÐ»Ð¸ÐµÐ½Ñ‚ {client_slug} - Ð¿Ñ€Ð°Ð¹Ñ Ð³Ð¾Ñ‚Ð¾Ð²')
    return


def converter_template(task):
    """
    Ð˜Ð· ÑÑ‚Ð¾ÐºÐ° ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð° Ð´ÐµÐ»Ð°ÐµÑ‚ ÑˆÐ°Ð±Ð»Ð¾Ð½ Ð´Ð»Ñ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚ÐµÑ€Ð°
    :param task: ÑÑ‚Ñ€Ð¾ÐºÐ° Ð¸Ð· Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ Ð—Ð°Ð´Ð°Ñ‡Ð¸ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚ÐµÑ€Ð°
    :return: ÑˆÐ°Ð±Ð»Ð¾Ð½ ÐºÐ°Ðº pandas dataframe
    """
    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÑŽ ÑÑ‚Ð¾Ðº ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°, Ð´ÐµÐ»Ð°ÑŽ Ð¿Ð¾ Ð½ÐµÐ¼Ñƒ ÑˆÐ°Ð±Ð»Ð¾Ð½ Ð´Ð»Ñ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚ÐµÑ€Ð°
    slug = task.client.slug
    file_date = str(datetime.datetime.now()).replace(' ', '_').replace(':', '-')
    stock_path = f'converter/{slug}/stocks/stock_{slug}_{file_date}'

    # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÑŽ ÑÑ‚Ð¾Ðº
    if task.stock_source == 'Ð¡ÑÑ‹Ð»ÐºÐ°':
        response = requests.get(url=task.stock_url)
    elif task.stock_source == 'POST-Ð·Ð°Ð¿Ñ€Ð¾Ñ':
        data = {
            'login': task.stock_post_login,
            'password': task.stock_post_password,
        }
        response = requests.post(url=task.stock_post_host, data=data)

    # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÑŽ Ñ‚Ð¸Ð¿ Ñ„Ð°Ð¹Ð»Ð° ÑÑ‚Ð¾ÐºÐ°
    content_type = response.headers['content-type']
    if 'text/xml' in content_type or 'application/xml' in content_type:
        stock_path += '.xml'
        content_type = 'xml'
    elif 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet' in content_type:
        stock_path += '.xlsx'
        content_type = 'xlsx'
    elif 'text/csv' in content_type:
        stock_path += '.csv'
        content_type = 'csv'

    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÑŽ ÑÑ‚Ð¾Ðº Ð½Ð° ftp
    os.makedirs(os.path.dirname(stock_path), mode=0o755, exist_ok=True)
    with open(stock_path, mode='wb') as file:
        file.write(response.content)
    # with open(stock_path, mode='w', encoding=task.stock_fields.encoding) as file:
    #     file.write(response.text)
    save_on_ftp(stock_path)

    # ÐŸÑƒÑ‚ÑŒ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð°
    template_path = f'converter/{slug}/templates/template_{slug}_{file_date}.xlsx'
    os.makedirs(os.path.dirname(template_path), exist_ok=True)
    task.template = template_path
    task.save()

    # Ð Ð°Ð·Ð½Ñ‹Ðµ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ Ñ‚Ð¸Ð¿Ð° Ñ„Ð°Ð¹Ð»Ð° ÑÑ‚Ð¾ÐºÐ°
    if content_type == 'xml':
        template = template_xml(stock_path, template_path, task)
    elif content_type == 'xlsx':
        template = template_xlsx_or_csv(stock_path, 'xlsx', template_path, task)
    elif content_type == 'csv':
        template = template_xlsx_or_csv(stock_path, 'csv', template_path, task)
    else:
        return 'ÐÐµÐ²ÐµÑ€Ð½Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ñ„Ð°Ð¹Ð»Ð°, Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ xml Ð¸Ð»Ð¸ xlsx'

    save_on_ftp(template_path)
    os.remove(stock_path)

    return template


def template_xml(stock_path, template_path, task):
    """
    Ð¨Ð°Ð±Ð»Ð¾Ð½ Ð¸Ð· xml ÑÑ‚Ð¾ÐºÐ°
    :param stock_path: Ð¿ÑƒÑ‚ÑŒ Ðº Ñ„Ð°Ð¹Ð»Ñƒ ÑÑ‚Ð¾ÐºÐ°
    :param template_path: Ð¿ÑƒÑ‚ÑŒ Ðº Ñ„Ð°Ð¹Ð»Ñƒ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð°
    :param task: ÑÑ‚Ñ€Ð¾ÐºÐ° Ð¸Ð· Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ Ð—Ð°Ð´Ð°Ñ‡Ð¸ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚ÐµÑ€Ð°
    :return: ÑˆÐ°Ð±Ð»Ð¾Ð½ ÐºÐ°Ðº pandas dataframe
    """
    # XML tree
    tree = ET.parse(stock_path)
    root = tree.getroot()

    # XLSX ÑˆÐ°Ð±Ð»Ð¾Ð½
    workbook = Workbook()
    workbook.active.title = 'Ð¨Ð°Ð±Ð»Ð¾Ð½'
    sheet = workbook.active

    # Ð—Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð°
    template_col = StockFields.TEMPLATE_COL
    for k, col in template_col.items():
        sheet.cell(row=1, column=col[1] + 1, value=col[0])

    # Ð”Ð°Ð½Ð½Ñ‹Ðµ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð°
    fields = task.stock_fields
    exception_col = ['modification_code', 'options_code', 'images', 'modification_explained']
    for i, car in enumerate(root.iter(fields.car_tag)):
        if stock_xml_filter(car, task):
            # ÐžÐ±Ñ‹Ñ‡Ð½Ñ‹Ðµ Ð¿Ð¾Ð»Ñ
            for field in fields._meta.fields:
                field_val = getattr(fields, field.name)
                # Ð•ÑÐ»Ð¸ Ð½Ðµ Ð¿ÑƒÑÑ‚Ð¾ Ð˜ Ð¿Ð¾Ð»Ðµ Ð² Ð¿Ð¾Ð»ÑÑ… ÑˆÐ°Ð±Ð»Ð¾Ð½Ð° Ð˜ Ð¿Ð¾Ð»Ðµ ÐÐ• Ð² Ð¸ÑÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸ÑÑ…
                if field_val and field.name in template_col and field.name not in exception_col:
                    cell = car.findtext(field_val)
                    try:
                        if cell.isnumeric():
                            cell = int(cell)
                    except AttributeError:
                        pass
                    sheet.cell(row=i + 2, column=template_col[field.name][1] + 1, value=cell)

            # ÐŸÐ¾Ð»Ñ-Ð¸ÑÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ
            if ',' in fields.modification_code:  # ÐšÐ¾Ð´ Ð¼Ð¾Ð´Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸
                # Ð Ð°Ð·Ð´ÐµÐ»ÑÐµÑ‚ Ð¿Ð¾ Ð·Ð°Ð¿ÑÑ‚Ð¾Ð¹ Ð² ÑÐ¿Ð¸ÑÐ¾Ðº ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ. Ð£Ð±Ð¸Ñ€Ð°ÐµÑ‚ Ð·Ð°Ð¿ÑÑ‚ÑƒÑŽ Ð¸Ð· Ð´Ð°Ð½Ð½Ñ‹Ñ… ÑÑ‚Ð¾ÐºÐ°
                mod = [car.findtext(f).replace(',', '') for f in fields.modification_code.split(', ') if
                       car.findtext(f)]
                sheet.cell(row=i + 2, column=template_col['modification_code'][1] + 1, value=' | '.join(mod))
            else:
                sheet.cell(row=i + 2, column=template_col['modification_code'][1] + 1,
                           value=car.findtext(fields.modification_code))

            if fields.options_code:
                options = multi_tags(fields.options_code, car)  # ÐžÐ¿Ñ†Ð¸Ð¸
                sheet.cell(row=i + 2, column=template_col['options_code'][1] + 1, value=options)

            if fields.images:
                if 'Ð°Ð²Ð¸Ð»Ð¾Ð½' in task.client.name.lower():
                    # ÐžÑÐ¾Ð±Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ñ„Ð¾Ñ‚Ð¾ Ð¾Ñ‚ ÐÐ²Ð¸Ð»Ð¾Ð½Ð°
                    images = avilon_photos(fields.images, car)
                else:
                    images = multi_tags(fields.images, car)  # Ð¤Ð¾Ñ‚Ð¾ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°
                sheet.cell(row=i + 2, column=template_col['images'][1] + 1, value=images)

            if ',' in fields.modification_explained:  # Ð Ð°ÑÑˆ. Ð¼Ð¾Ð´Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸
                mod = [car.findtext(f) for f in fields.modification_explained.split(', ') if car.findtext(f)]
                sheet.cell(row=i + 2, column=template_col['modification_explained'][1] + 1, value=' | '.join(mod))
            else:
                sheet.cell(row=i + 2, column=template_col['modification_explained'][1] + 1,
                           value=car.findtext(fields.modification_explained))

            # Ð”Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð¿Ñ€Ð°Ð¹ÑÐ° ÐºÐ¾Ð³Ð´Ð° Ð½ÑƒÐ¶Ð½Ð¾ ÑÐ¼Ð¾Ñ‚Ñ€ÐµÑ‚ÑŒ Ð¿Ð¾ ÑÑ‚Ð¾ÐºÑƒ. Ð”Ð¾Ð±Ð°Ð²Ð»ÑÑŽ ÑÑ‚Ð¾Ð»Ð±ÐµÑ† Ðº ÑˆÐ°Ð±Ð»Ð¾Ð½Ñƒ
            extras = ConverterExtraProcessing.objects.filter(converter_task=task, source='Ð¡Ñ‚Ð¾Ðº')
            if extras:
                for extra in extras:
                    conditionals = Conditionals.objects.filter(converter_extra_processing=extra.id)
                    for cond in conditionals:
                        column_name = cond.field
                        value = multi_tags(cond.field, car)

                        if column_name not in template_col:
                            max_column = len(template_col)
                            template_col[column_name] = (column_name, max_column)
                            sheet.cell(row=1, column=max_column + 1, value=column_name)

                        column_number = template_col[column_name][1] + 1

                        sheet.cell(row=i + 2, column=column_number, value=value)

    # Ð£Ð´Ð°Ð»ÑÑŽ Ð¿ÑƒÑÑ‚Ñ‹Ðµ ÑÑ‚Ñ€Ð¾ÐºÐ¸
    for row in reversed(range(1, sheet.max_row + 1)):
        if all(cell.value is None for cell in sheet[row]):
            sheet.delete_rows(row)

    workbook.save(filename=template_path)
    return pd.read_excel(template_path, decimal=',')


def avilon_photos(field: str, element: ET.Element) -> str:
    """
    ÐžÑÐ¾Ð±Ð°Ñ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð´Ð»Ñ ÐÐ²Ð¸Ð»Ð¾Ð½Ð°. Ð•ÑÐ»Ð¸ Ð±Ñ€Ð°Ñ‚ÑŒ Ð¸Ñ… Ñ„Ð¾Ñ‚Ð¾ Ð² Ñ‚Ð¾Ð¼ Ð¿Ð¾Ñ€ÑÐ´ÐºÐµ ÐºÐ°Ðº Ð¾Ð½Ð¸ Ð¸Ð´ÑƒÑ‚ Ð² xml,
    Ñ‚Ð¾ Ð¿Ð¾Ñ€ÑÐ´Ð¾Ðº Ñ„Ð¾Ñ‚Ð¾ Ð¿Ð¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ÑÑ ÑÐ»ÑƒÑ‡Ð°Ð¹Ð½Ñ‹Ð¼. Ð Ñ‚Ð°Ðº ÐºÐ°Ðº ÐÐ²Ð¸Ð»Ð¾Ð½ Ðº ÐºÐ°Ð¶Ð´Ð¾Ð¼Ñƒ Ñ„Ð¾Ñ‚Ð¾ ÑƒÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚ ÑƒÐ³Ð¾Ð»,
    Ñ ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ð³Ð¾ Ð¾Ð½Ð¸ ÑÐ½Ð¸Ð¼Ð°Ð»Ð¸, Ñ‚Ð¾ Ð¼Ð¾Ð¶Ð½Ð¾ Ð¿Ð¾ ÑÑ‚Ð¾Ð¼Ñƒ ÑƒÐ³Ð»Ñƒ Ð²Ñ‹ÑÑ‚Ð°Ð²Ð»ÑÑ‚ÑŒ Ð² ÐºÑ€Ð°ÑÐ¸Ð²Ñ‹Ð¹ Ð¿Ð¾Ñ€ÑÐ´Ð¾Ðº Ñ„Ð¾Ñ‚Ð¾
    :param field: Ð¸Ð¼Ñ Ñ‚ÑÐ³Ð° Ñ Ñ„Ð¾Ñ‚Ð¾
    :param element: ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚ Ð°Ð²Ñ‚Ð¾Ð¼Ð¾Ð±Ð¸Ð»Ñ
    :return: Ñ„Ð¾Ñ‚Ð¾ Ð² Ð¾Ð´Ð½Ð¾Ð¹ ÑÑ‚Ñ€Ð¾ÐºÐµ, Ñ€Ð°Ð·Ð´ÐµÐ»Ñ‘Ð½Ð½Ñ‹Ðµ Ð·Ð°Ð¿ÑÑ‚Ð¾Ð¹
    """

    def get_by_view_type(tags, view_type):
        return [tag for tag in tags if tag.attrib['view_type'] == view_type]

    tags = element.findall(field)

    exterior = get_by_view_type(tags, 'exterior')
    # ÐŸÐµÑ€Ð²Ð¾Ðµ Ñ„Ð¾Ñ‚Ð¾ Ð½ÐµÐ¼Ð½Ð¾Ð³Ð¾ Ð±Ð¾ÐºÐ¾Ð¼ Ð²Ð»ÐµÐ²Ð¾
    for element in exterior:
        if element.attrib['angle'] in ['40', '320']:
            element.set('angle', '-40')
            break
    exterior.sort(key=lambda x: float(x.get('angle')))

    detail = get_by_view_type(tags, 'detail')

    interior = get_by_view_type(tags, 'interior')

    images = [image.text for image in exterior]
    images += [image.text for image in detail]
    images += [image.text for image in interior]
    return ', '.join(images)


def stock_xml_filter(car, task):
    """
    ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ Ð°Ð²Ñ‚Ð¾Ð¼Ð¾Ð±Ð¸Ð»ÑŒ Ð¸Ð· xml ÑÑ‚Ð¾ÐºÐ° Ð¿Ð¾ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ð¼ Ð¸Ð· ConverterFilters
    :param car: node Ð°Ð²Ñ‚Ð¾Ð¼Ð¾Ð±Ð¸Ð»Ñ Ð¸Ð· xml ÑÑ‚Ð¾ÐºÐ°
    :param task: task (Ð·Ð°Ð¿Ð¸ÑÑŒ) Ð¸Ð· Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ Ð—Ð°Ð´Ð°Ñ‡Ð¸ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚ÐµÑ€Ð°
    :return: True ÐµÑÐ»Ð¸ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ñ‹ Ð¿Ñ€Ð¾Ð¹Ð´ÐµÐ½Ñ‹
    """
    filters = ConverterFilters.objects.filter(converter_task=task)
    dict_filters, stock_fields, result = [], [], []

    # ÐŸÐµÑ€ÐµÐ²Ð¾Ð¶Ñƒ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ñ‹ Ð² ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ð²Ð¸Ð´Ð°: {'values': values, 'condition': condition, 'field': field}
    for f in filters:
        # Ð—Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ
        if '`' in f.value:
            values = [val.replace('`', '').strip() for val in f.value.split('`,')]
        else:
            values = [f.value]

        # ÐŸÐ¾Ð»Ñ (Ñ‚ÐµÐ³Ð¸)
        if '/' in f.field:  # ÐŸÑƒÑ‚ÑŒ Ðº Ð´ÐµÑ‚ÑÐ¼
            parent = f.field.split('/')[0]

            if '@' not in f.field:  # Ð”ÐµÑ‚Ð¸
                stock_fields = [tag.text for tag in car.find(parent)]

            else:  # ÐÑ‚Ñ€Ð¸Ð±ÑƒÑ‚Ñ‹
                attribute_name = f.field.split('@')[1].split('=')[0]
                attribute_value = f.field.split('"')[1].replace('"', '')
                for tag in car.find(parent):
                    for tag_attribute in tag.attrib.items():
                        if tag_attribute == (attribute_name, attribute_value):
                            stock_fields = [tag.text]

        else:  # ÐŸÑ€Ð¾ÑÑ‚Ð¾ Ð¾Ð´Ð¸Ð½ Ñ‚ÐµÐ³
            stock_fields = [car.findtext(f.field)]

        for field in stock_fields:
            dict_filters.append({
                'values': values,
                'condition': f.condition,
                'field': field,
            })

    for sf in dict_filters:
        for value in sf['values']:
            result.append(xml_filter_conditions(value, sf['condition'], sf['field']))

    # Ð•ÑÐ»Ð¸ Ð´Ð»Ð¸Ð½Ð° Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð¾Ð² Ñ€Ð°Ð²Ð½Ð° ÑÑƒÐ¼Ð¼Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð·Ð½Ð°Ñ‡Ð¸Ñ‚ ÐºÐ°Ð¶Ð´Ñ‹Ð¹ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€ Ð²ÐµÑ€Ð½ÑƒÐ» True, ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÐµÐ½Ð½Ð¾ Ð°Ð²Ñ‚Ð¾Ð¼Ð¾Ð±Ð¸Ð»ÑŒ Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð¸Ñ‚
    return len(dict_filters) == sum(result)


def xml_filter_conditions(value, condition, stock_field):
    """
    Ð£ÑÐ»Ð¾Ð²Ð¸Ñ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°
    :param value: Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸
    :param condition: ÑƒÑÐ»Ð¾Ð²Ð¸Ðµ
    :param stock_field: Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ Ð¸Ð· ÑÑ‚Ð¾ÐºÐ°
    :return: True ÐµÑÐ»Ð¸ ÑƒÑÐ»Ð¾Ð²Ð¸Ðµ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¾
    """
    if condition == ConverterFilters.GREATER_THAN:
        if not stock_field:
            stock_field = 0
        return eval(f'{int(stock_field)} {condition} {int(value)}')
    elif condition == ConverterFilters.LESS_THAN:
        if not stock_field:
            stock_field = 0
        return eval(f'{int(stock_field)} {condition} {int(value)}')
    elif 'with' not in condition:
        return eval(f'"{value}" {condition} "{stock_field}"')
    elif condition == ConverterFilters.STARTS_WITH:
        return stock_field.startswith(value)
    elif condition == ConverterFilters.NOT_STARTS_WITH:
        return not (stock_field.startswith(value))
    elif condition == ConverterFilters.ENDS_WITH:
        return stock_field.endswith(value)
    elif condition == ConverterFilters.NOT_ENDS_WITH:
        return not (stock_field.endswith(value))


def template_xlsx_or_csv(stock_path, filetype, template_path, task):
    """
    Ð¨Ð°Ð±Ð»Ð¾Ð½ Ð¸Ð· xlsx Ð¸Ð»Ð¸ csv ÑÑ‚Ð¾ÐºÐ°
    :param stock_path: Ð¿ÑƒÑ‚ÑŒ Ðº Ñ„Ð°Ð¹Ð»Ñƒ ÑÑ‚Ð¾ÐºÐ°
    :param filetype: Ñ‚Ð¸Ð¿ Ñ„Ð°Ð¹Ð»Ð°: 'xlsx' Ð¸Ð»Ð¸ 'csv'
    :param template_path: Ð¿ÑƒÑ‚ÑŒ Ðº Ñ„Ð°Ð¹Ð»Ñƒ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð°
    :param task: ÑÑ‚Ñ€Ð¾ÐºÐ° Ð¸Ð· Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ Ð—Ð°Ð´Ð°Ñ‡Ð¸ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚ÐµÑ€Ð°
    :return: ÑˆÐ°Ð±Ð»Ð¾Ð½ ÐºÐ°Ðº pandas dataframe
    """
    if filetype == 'xlsx':
        df_stock = pd.read_excel(stock_path, decimal=',')
    elif filetype == 'csv':
        df_stock = pd.read_csv(stock_path, decimal=',', sep=';', header=0, encoding='cp1251')
    else:
        return 'ÐÐµÐ²ÐµÑ€Ð½Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ñ„Ð°Ð¹Ð»Ð°, Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ xlsx Ð¸Ð»Ð¸ csv'

    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÑŽ ÐµÑÐ»Ð¸ ÑÑ‚Ð¾Ðº ÑÑ‚Ð¾ Ð½Ð°Ñˆ Ð¿Ñ€Ð°Ð¹Ñ. ÐÐ° ÑÐ»ÑƒÑ‡Ð°Ð¹ ÐµÑÐ»Ð¸ Ð¿Ñ€Ð°Ð¹Ñ Ð³Ð¾Ñ‚Ð¾Ð² Ð¸ Ð½ÑƒÐ¶Ð½Ð¾ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ„Ð¾Ñ‚Ð¾ Ð¿Ð¾Ð´ÑÑ‚Ð°Ð²Ð¸Ñ‚ÑŒ
    # Ð•ÑÐ»Ð¸ Ð¿ÐµÑ€Ð²Ñ‹Ðµ 4 ÑÑ‚Ð¾Ð»Ð±Ñ†Ð° ÑÐ¾Ð²Ð¿Ð°Ð´Ð°ÑŽÑ‚ Ñ our_price_first_4_cols Ð˜ Ð˜ÑÑ…Ð¾Ð´Ð½Ñ‹Ð¹ VIN Ð² ÑÑ‚Ð¾Ð»Ð±Ñ†Ð°Ñ…
    our_price_first_4_cols = ['ÐœÐ°Ñ€ÐºÐ°', 'ÐœÐ¾Ð´ÐµÐ»ÑŒ', 'ÐšÐ¾Ð¼Ð¿Ð»ÐµÐºÑ‚Ð°Ñ†Ð¸Ñ', 'ÐÐ²Ñ‚Ð¾.Ñ€Ñƒ ÐšÐ¾Ð¼Ð¿Ð»ÐµÐºÑ‚Ð°Ñ†Ð¸Ñ']
    if list(df_stock.columns[:4]) == our_price_first_4_cols and 'Ð˜ÑÑ…Ð¾Ð´Ð½Ñ‹Ð¹ VIN' in df_stock.columns:
        df_stock.loc[df_stock['Ð¤Ð¾Ñ‚Ð¾'].str.contains('gallery'), 'Ð¤Ð¾Ñ‚Ð¾'] = ''
        df_stock.T.reset_index().T.to_excel(template_path, sheet_name='Ð¨Ð°Ð±Ð»Ð¾Ð½', header=False, index=False)
        return df_stock

    df_stock = stock_xlsx_filter(df_stock, task)

    fields = StockFields.objects.filter(pk=task.stock_fields.id)
    fields = fields.values()[0]
    template_col = StockFields.TEMPLATE_COL

    # ÐœÐµÐ½ÑÑŽ Ð¸Ð¼ÐµÐ½Ð° ÑÑ‚Ð¾Ð»Ð±Ñ†Ð¾Ð²
    swapped_cols = {v: template_col[k][0] for k, v in fields.items() if k in template_col}
    df_stock.rename(columns=swapped_cols, inplace=True)

    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÑŽ Ð½ÐµÐ´Ð¾ÑÑ‚Ð°ÑŽÑ‰Ð¸Ðµ ÑÑ‚Ð¾Ð»Ð±Ñ†Ñ‹
    cur_cols = list(df_stock.columns.values)
    for k, col in template_col.items():
        if col[0] not in cur_cols:
            df_stock[col[0]] = ''

    # Ð”Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð¿Ñ€Ð°Ð¹ÑÐ° ÐºÐ¾Ð³Ð´Ð° Ð½ÑƒÐ¶Ð½Ð¾ ÑÐ¼Ð¾Ñ‚Ñ€ÐµÑ‚ÑŒ Ð¿Ð¾ ÑÑ‚Ð¾ÐºÑƒ. Ð”Ð¾Ð±Ð°Ð²Ð»ÑÑŽ ÑÑ‚Ð¾Ð»Ð±ÐµÑ† Ðº ÑˆÐ°Ð±Ð»Ð¾Ð½Ñƒ
    extras = ConverterExtraProcessing.objects.filter(converter_task=task, source='Ð¡Ñ‚Ð¾Ðº')
    if extras:
        for extra in extras:
            conditionals = Conditionals.objects.filter(converter_extra_processing=extra.id)
            for cond in conditionals:
                column_name = cond.field
                if column_name not in template_col:
                    max_column = len(template_col)
                    template_col[column_name] = (column_name, max_column)

    # ÐžÑÑ‚Ð°Ð²Ð»ÑÑŽ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½ÑƒÐ¶Ð½Ñ‹Ðµ ÑÑ‚Ð¾Ð»Ð±Ñ†Ñ‹ Ð² Ñ‚Ð¾Ð¼ Ð¿Ð¾Ñ€ÑÐ´ÐºÐµ ÐºÐ°Ðº Ð² template_col
    df_stock = df_stock[[v[0] for k, v in template_col.items()]]
    # Ð’ ÐžÐ¿Ñ†Ð¸Ð¸ Ð¸ Ð¿Ð°ÐºÐµÑ‚Ñ‹ Ð·Ð°Ð¼ÐµÐ½ÑÑŽ Ð¿ÐµÑ€ÐµÐ½Ð¾ÑÑ‹ ÑÑ‚Ñ€Ð¾Ðº Ð½Ð° Ð¿Ñ€Ð¾Ð±ÐµÐ»
    df_stock['ÐžÐ¿Ñ†Ð¸Ð¸ Ð¸ Ð¿Ð°ÐºÐµÑ‚Ñ‹'].replace(r'\n', ' ', regex=True, inplace=True)

    df_stock.T.reset_index().T.to_excel(template_path, sheet_name='Ð¨Ð°Ð±Ð»Ð¾Ð½', header=False, index=False)

    return df_stock


def stock_xlsx_filter(df, task):
    """
    ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ Ð°Ð²Ñ‚Ð¾Ð¼Ð¾Ð±Ð¸Ð»ÑŒ Ð¸Ð· xlsx ÑÑ‚Ð¾ÐºÐ° Ð¿Ð¾ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ð¼ Ð¸Ð· ConverterFilters
    :param df: xlsx ÑÑ‚Ð¾Ðº Ð² Ð²Ð¸Ð´Ðµ pandas dataframe
    :param task: task (Ð·Ð°Ð¿Ð¸ÑÑŒ) Ð¸Ð· Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ Ð—Ð°Ð´Ð°Ñ‡Ð¸ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚ÐµÑ€Ð°
    :return: ÐžÑ‚Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ dataframe
    """
    filters = ConverterFilters.objects.filter(converter_task=task)
    filter_strings = []
    for f in filters:
        filter_or = []
        if '`' in f.value:
            values = [val.replace('`', '').strip() for val in f.value.split('`,')]
        else:
            values = [f.value]

        for value in values:
            if f.condition == ConverterFilters.CONTAINS:
                filter_or.append(f'(df["{f.field}"].str.contains({value})')
            elif f.condition == ConverterFilters.NOT_CONTAINS:
                filter_or.append(f'(~df["{f.field}"].str.contains({value})')
            elif f.condition == ConverterFilters.EQUALS:
                filter_or.append(f'(df["{f.field}"] == "{value}")')
            elif f.condition == ConverterFilters.NOT_EQUALS:
                filter_or.append(f'(~df["{f.field}"] == "{value}")')
            elif f.condition == ConverterFilters.GREATER_THAN:
                filter_or.append(f'(df["{f.field}"] > "{value}")')
            elif f.condition == ConverterFilters.LESS_THAN:
                filter_or.append(f'(df["{f.field}"] < "{value}")')
            elif f.condition == ConverterFilters.STARTS_WITH:
                filter_or.append(f'(df["{f.field}"].str.startswith("{value}"))')
            elif f.condition == ConverterFilters.NOT_STARTS_WITH:
                filter_or.append(f'~(df["{f.field}"].str.startswith("{value}"))')
            elif f.condition == ConverterFilters.ENDS_WITH:
                filter_or.append(f'(df["{f.field}"].str.endswith("{value}"))')
            elif f.condition == ConverterFilters.NOT_ENDS_WITH:
                filter_or.append(f'~(df["{f.field}"].str.endswith("{value}"))')

        filter_strings.append(f'({" | ".join(filter_or)})')

    return eval(f'df.loc[{" & ".join(filter_strings)}]') if filter_strings else df


def price_extra_processing(df: DataFrame, task: ConverterTask, template: DataFrame) -> DataFrame:
    """
    ÐœÐµÐ½ÑÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð² Ð¿Ñ€Ð°Ð¹ÑÐµ Ð¿Ð¾ ÑƒÑÐ»Ð¾Ð²Ð¸ÑŽ
    :param df: Ð¿Ñ€Ð°Ð¹Ñ Ð² Ð²Ð¸Ð´Ðµ pandas dataframe
    :param task: task (Ð·Ð°Ð¿Ð¸ÑÑŒ) Ð¸Ð· Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ Ð—Ð°Ð´Ð°Ñ‡Ð¸ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚ÐµÑ€Ð°
    :param template: ÑˆÐ°Ð±Ð»Ð¾Ð½ Ð² Ð²Ð¸Ð´Ðµ pandas dataframe
    :return: Ð“Ð¾Ñ‚Ð¾Ð²Ñ‹Ð¹ Ð¿Ñ€Ð°Ð¹Ñ Ñ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸ÑÐ¼Ð¸
    """
    changes = ConverterExtraProcessing.objects.filter(converter_task=task)

    # Ð•ÑÐ»Ð¸ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ðµ Ð·Ð°Ð²Ð¸ÑÐ¸Ñ‚ Ð¾Ñ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð² ÑÑ‚Ð¾ÐºÐµ Ñ‚Ð¾ ÑÐ½Ð°Ñ‡Ð°Ð»Ð° ÑÑ‚Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÑŽÑ‚ÑÑ Ðº ÑˆÐ°Ð±Ð»Ð¾Ð½Ñƒ.
    # ÐŸÐ¾Ñ‚Ð¾Ð¼ ÑˆÐ°Ð±Ð»Ð¾Ð½ Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‘Ñ‚ÑÑ ÑÑŽÐ´Ð° Ð¸ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÑ‚ÑÑ Ðº Ð¿Ñ€Ð°Ð¹ÑÑƒ.
    if changes.filter(source='Ð¡Ñ‚Ð¾Ðº'):
        template = template.add_suffix('_template')
        df = pd.merge(df, template, left_index=True, right_index=True)

    # Ð”Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ Ð¿Ð¾ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ñƒ
    for change in changes:
        conditionals = Conditionals.objects.filter(converter_extra_processing=change.id)
        masks = []

        # Ð”Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ ÑƒÑÐ»Ð¾Ð²Ð¸Ñ Ð² Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ð¸
        for cond in conditionals:

            if change.source == 'Ð¡Ñ‚Ð¾Ðº':
                cond.field += '_template'

            # Ð•ÑÐ»Ð¸ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹
            if '`' in cond.value:
                values = [val.replace('`', '').strip() for val in cond.value.split('`,')]
            else:
                values = [cond.value]

            # Ð”Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ
            or_masks = []
            for value in values:
                if value.isdigit():
                    value = int(value)

                if cond.condition == ConverterFilters.CONTAINS:
                    or_masks.append(df[cond.field].str.contains(value))
                elif cond.condition == ConverterFilters.NOT_CONTAINS:
                    or_masks.append(~df[cond.field].str.contains(value))
                elif cond.condition == ConverterFilters.EQUALS:
                    or_masks.append(df[cond.field] == value)
                elif cond.condition == ConverterFilters.NOT_EQUALS:
                    or_masks.append(df[cond.field] != value)
                elif cond.condition == ConverterFilters.GREATER_THAN:
                    or_masks.append(df[cond.field] > value)
                elif cond.condition == ConverterFilters.LESS_THAN:
                    or_masks.append(df[cond.field] < value)
                elif cond.condition == ConverterFilters.STARTS_WITH:
                    or_masks.append(df[cond.field].str.startswith(value))
                elif cond.condition == ConverterFilters.NOT_STARTS_WITH:
                    or_masks.append(~df[cond.field].str.startswith(value))
                elif cond.condition == ConverterFilters.ENDS_WITH:
                    or_masks.append(df[cond.field].str.endswith(value))
                elif cond.condition == ConverterFilters.NOT_ENDS_WITH:
                    or_masks.append(~df[cond.field].str.endswith(value))

            # ÐÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹ Ñ‡ÐµÑ€ÐµÐ· Ð˜Ð›Ð˜
            combined_or_mask = reduce(lambda x, y: x | y, or_masks)
            combined_or_mask = combined_or_mask.fillna(False)
            masks.append(combined_or_mask)

        # ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÑÑŽ Ð¼Ð°ÑÐºÐ¸
        combined_mask = reduce(lambda x, y: x & y, masks)
        # ÐŸÑ€Ð¾ÑÑ‚Ð°Ð²Ð»ÑÑŽ Ð½Ð¾Ð²Ñ‹Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ
        df.loc[combined_mask, change.price_column_to_change] = change.new_value

    df = df.drop(df.filter(regex='_template').columns, axis=1)

    return df


def multi_tags(field, element):
    """
    ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ð¿Ð¾Ð»Ñ Ð´Ð»Ñ ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ðµ ÑÐ¾Ð±Ð¸Ñ€Ð°ÑŽÑ‚ÑÑ Ð¸Ð· Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¸Ñ… Ñ‚ÐµÐ³Ð¾Ð²
    :param field: Ð¿Ð¾Ð»Ðµ
    :param element: ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚ Ð¸Ð· xml
    :return: Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð°
    """
    result = []

    if '/' in field:
        parent = field.split('/')[0]
        parent_element = element.find(parent)
        if parent_element:
            if '@' not in field:  # Ð•ÑÐ»Ð¸ Ñ‚ÐµÐ³ Ñ Ð´ÐµÑ‚ÑŒÐ¼Ð¸ Ð¸ Ð½ÑƒÐ¶Ð½Ð¾ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ Ð´ÐµÑ‚ÐµÐ¹
                result = [tag.text for tag in parent_element]
            else:  # Ð•ÑÐ»Ð¸ Ñ‚ÐµÐ³ Ñ Ð´ÐµÑ‚ÑŒÐ¼Ð¸ Ð¸ Ð¸Ð· Ð´ÐµÑ‚ÐµÐ¹ Ð½ÑƒÐ¶ÐµÐ½ Ð°Ñ‚Ñ€Ð¸Ð±ÑƒÑ‚
                attribute = field.split('@')[1]
                result = [tag.attrib[attribute] for tag in parent_element]
    else:
        if '@' not in field:  # Ð•ÑÐ»Ð¸ Ñ‚ÐµÐ³ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ñ€Ð°Ð· Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑÐµÑ‚ÑÑ Ð¸ Ð½ÑƒÐ¶Ð½Ð¾ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ
            tags = element.findall(field)
            if tags:
                result = [tag.text for tag in tags]
        else:  # Ð•ÑÐ»Ð¸ Ñ‚ÐµÐ³ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ñ€Ð°Ð· Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑÐµÑ‚ÑÑ Ð¸ Ð¸Ð· Ð½ÐµÐ³Ð¾ Ð½ÑƒÐ¶ÐµÐ½ Ð°Ñ‚Ñ€Ð¸Ð±ÑƒÑ‚
            tag_name, attribute = field.split('@')
            tags = element.findall(tag_name)
            if tags:
                result = [tag.attrib[attribute] for tag in tags]

    return ' '.join(result)


def converter_post(task):
    """
    ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÑ‚ ÑˆÐ°Ð±Ð»Ð¾Ð½ Ð¸ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ð¿Ð¾ ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¼ Ð½ÑƒÐ¶Ð½Ð¾ Ð¿Ñ€Ð¾Ð³Ð½Ð°Ñ‚ÑŒ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚ÐµÑ€
    :param task: task (Ð·Ð°Ð¿Ð¸ÑÑŒ) Ð¸Ð· Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ Ð—Ð°Ð´Ð°Ñ‡Ð¸ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚ÐµÑ€Ð°
    :return: Ð¿Ñ€Ð°Ð¹Ñ ÐºÐ°Ðº pandas dataframe
    """
    # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÑŽ ÑˆÐ°Ð±Ð»Ð¾Ð½
    url = 'http://151.248.118.19/Api/Stock/StartProcess'

    configuration = task.configuration.configuration if task.configuration is not None else Configuration.DEFAULT
    payload = {
        'client': task.photos_folder.folder,
        'configuration': configuration,
        'frontLength': task.front,
        'backLength': task.back,
        'interiorsLength': task.interior,
        'onlySalon': task.salon_only,
    }
    template = open(task.template, 'rb')
    files = {'file': ('template.xlsx', template, 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                      {'Expires': '0'})}
    response = requests.post(url=url, data=payload, files=files)
    template.close()
    os.remove(task.template)
    return response.json()['processId']


def converter_process_result(process_id, client, template, task):
    """
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹Ð¹ Ð¿Ñ€Ð°Ð¹Ñ
    :param process_id: Ð¸Ð· converter_post
    :param client: Ð¸Ð¼Ñ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð° ÐºÐ°Ðº slug - Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ ÐºÐ°Ðº Ð¸Ð¼Ñ Ð¿Ð°Ð¿ÐºÐ¸ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð° ÐºÑƒÐ´Ð° ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ÑÑ Ð¿Ñ€Ð°Ð¹Ñ
    :param template: ÑˆÐ°Ð±Ð»Ð¾Ð½ ÐºÐ°Ðº pandas dataframe - ÐµÑÐ»Ð¸ Ð¸Ð· ÑˆÐ°Ð±Ð»Ð¾Ð½Ð° Ð½ÑƒÐ¶Ð½Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ð¿Ñ€Ð°Ð¹ÑÐ°
    :param task: ÑÑ‚Ñ€Ð¾ÐºÐ° Ð¸Ð· Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ Ð—Ð°Ð´Ð°Ñ‡Ð¸ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚ÐµÑ€Ð°
    """
    # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÑŽ Ð¿Ñ€Ð°Ð¹Ñ Ð¾Ñ‚ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚ÐµÑ€Ð° Ð¿Ð¾ process_id
    url = 'http://151.248.118.19/Api/Stock/GetProcessResult'
    payload = {'processId': (None, process_id)}
    response = requests.post(url=url, files=payload)

    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÑŽ Ð¿Ñ€Ð°Ð¹Ñ Ð² xlsx
    file_date = str(datetime.datetime.now()).replace(' ', '_').replace(':', '-')
    save_path_date = f'converter/{client}/prices/price_{client}_{file_date}.xlsx'
    os.makedirs(os.path.dirname(save_path_date), exist_ok=True)
    with open(save_path_date, 'wb') as file:
        file.write(response.content)
    save_on_ftp(save_path_date)

    # ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð¿Ñ€Ð°Ð¹ÑÐ°
    read_file = pd.read_excel(save_path_date, decimal=',')
    # ÐŸÐµÑ€ÐµÐ½Ð¾ÑˆÑƒ ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð¸Ð· ÑˆÐ°Ð±Ð»Ð¾Ð½Ð° ÐµÑÐ»Ð¸ Ð¾Ð½Ð¾ ÐµÑÑ‚ÑŒ Ð² ÑˆÐ°Ð±Ð»Ð¾Ð½Ðµ
    if 'ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ' in template.columns:
        read_file['ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ2'] = template['ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ']
        read_file.loc[read_file['ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ2'].notnull(), 'ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ'] = read_file['ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ2']
        read_file.drop(columns='ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ2', inplace=True)

    read_file['ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ'] = read_file['ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ'].replace('_x000d_', '', regex=True)

    # Ð£Ð±Ð¸Ñ€Ð°ÑŽ Ð°Ð²Ñ‚Ð¾Ð¼Ð¾Ð±Ð¸Ð»Ð¸ ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð½Ðµ Ñ€Ð°ÑÑˆÐ¸Ñ„Ñ€Ð¾Ð²Ð°Ð½Ñ‹ (Ð¿ÑƒÑÑ‚Ñ‹Ðµ ÑÑ‚Ð¾Ð»Ð±Ñ†Ñ‹ ÐœÐ°Ñ€ÐºÐ°, Ð¦Ð²ÐµÑ‚ Ð»Ð¸Ð±Ð¾ Ð¤Ð¾Ñ‚Ð¾)
    read_file = read_file[(~read_file['ÐœÐ°Ñ€ÐºÐ°'].isnull()) &
                          (~read_file['Ð¦Ð²ÐµÑ‚'].isnull()) &
                          (~read_file['Ð¤Ð¾Ñ‚Ð¾'].isnull())]
    # Ð•ÑÐ»Ð¸ ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÐºÐ° Ð¿ÑƒÑÑ‚Ð°Ñ Ñ‚Ð¾ ÑÑ‡Ð¸Ñ‚Ð°Ñ‚ÑŒ ÐµÑ‘ ÐºÐ°Ðº ÑÑƒÐ¼Ð¼Ñƒ Ð´Ñ€ÑƒÐ³Ð¸Ñ… ÑÐºÐ¸Ð´Ð¾Ðº
    read_file.loc[read_file['ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÐºÐ°'].isna(), 'ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÐºÐ°'] = read_file[['Ð¢Ñ€ÐµÐ¹Ð´-Ð¸Ð½', 'ÐšÑ€ÐµÐ´Ð¸Ñ‚', 'Ð¡Ñ‚Ñ€Ð°Ñ…Ð¾Ð²ÐºÐ°']].sum(
        axis=1)

    # Ð Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ðµ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð°Ð¹ÑÐ° Ð¿Ð¾ ÑƒÑÐ»Ð¾Ð²Ð¸ÑŽ
    read_file = price_extra_processing(read_file, task, template)

    read_file.fillna('', inplace=True)
    read_file = read_file.astype(str).replace(r'\.0$', '', regex=True)
    read_file = read_file.astype(str).replace('Ã©', 'e', regex=True)

    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÑŽ Ð² csv
    save_path = f'converter/{client}/prices/price_{client}.csv'
    read_file.to_csv(save_path, sep=';', header=True, encoding='cp1251', index=False, decimal=',')
    save_on_ftp(save_path)

    os.remove(save_path_date)
    os.remove(save_path)
    return read_file


def converter_logs(process_id):
    """
    Ð›Ð¾Ð³Ð¸ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚ÐµÑ€Ð°
    :return: Ð»Ð¾Ð³Ð¸ Ð² Ð²Ð¸Ð´Ðµ Ñ‚ÐµÐºÑÑ‚Ð°
    """
    # Ð›Ð¾Ð³Ð¸ ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð¿Ñ€Ð¸ÑÑ‹Ð»Ð°ÐµÑ‚ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚ÐµÑ€
    url = 'http://151.248.118.19/Api/Log/GetByProcessId'
    payload = {'processId': process_id}
    response = requests.post(url=url, json=payload)
    logs = response.json()['log']
    logs = logs.replace(' ,', '')  # Ð£Ð±Ð¸Ñ€Ð°ÑŽ Ð»Ð¸ÑˆÐ½Ð¸Ðµ Ð·Ð°Ð¿ÑÑ‚Ñ‹Ðµ
    return logs


def logs_to_xlsx(logs, template, client):
    """
    Ð›Ð¾Ð³Ð¸ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚ÐµÑ€Ð° Ð²Ð¼ÐµÑÑ‚Ðµ Ñ Ñ€Ð°ÑÑˆÐ¸Ñ„Ñ€Ð¾Ð²ÐºÐ¾Ð¹ Ð² xlsx
    :param logs: Ð»Ð¾Ð³Ð¸ Ð¾Ñ‚ converter_logs
    :param template: ÑˆÐ°Ð±Ð»Ð¾Ð½ Ð¾Ñ‚ converter_template
    :param client: ÐºÐ»Ð¸ÐµÐ½Ñ‚ ÐºÐ°Ðº client_slug Ð´Ð»Ñ Ð¸Ð¼ÐµÐ½Ð¸ Ð¿Ð°Ð¿ÐºÐ¸ Ð¸ Ñ„Ð°Ð¹Ð»Ð°
    :return: xlsx Ñ„Ð°Ð¹Ð» Ð»Ð¾Ð³Ð¾Ð²
    """
    lookup_cols = {
        # Ð‘Ð°Ð·Ð° Ð¸Ð· Ð»Ð¾Ð³Ð°: (Ð˜Ð¼Ñ ÑÑ‚Ð¾Ð»Ð±Ñ†Ð° Ñ ÐºÐ¾Ð´Ð¾Ð¼, Ð˜Ð¼Ñ ÑÑ‚Ð¾Ð»Ð±Ñ†Ð° Ñ Ñ€Ð°ÑÑˆÐ¸Ñ„Ñ€Ð¾Ð²ÐºÐ¾Ð¹)
        'ÐœÐ¾Ð´Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸': ('ÐšÐ¾Ð´ Ð¼Ð¾Ð´Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸', 'Ð Ð°ÑÑˆ. Ð¼Ð¾Ð´Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸'),
        'Ð¦Ð²ÐµÑ‚Ð°': ('ÐšÐ¾Ð´ Ñ†Ð²ÐµÑ‚Ð°', 'Ð Ð°ÑÑˆ. Ñ†Ð²ÐµÑ‚Ð°'),
        'Ð˜Ð½Ñ‚ÐµÑ€ÑŒÐµÑ€Ñ‹': ('ÐšÐ¾Ð´ Ð¸Ð½Ñ‚ÐµÑ€ÑŒÐµÑ€Ð°', 'Ð Ð°ÑÑˆ. Ð¸Ð½Ñ‚ÐµÑ€ÑŒÐµÑ€Ð°'),
        'ÐšÐ¾Ð¼Ð¿Ð»ÐµÐºÑ‚Ð°Ñ†Ð¸Ð¸': ('ÐšÐ¾Ð´ Ð¼Ð¾Ð´Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸', 'Ð Ð°ÑÑˆ. Ð¼Ð¾Ð´Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸'),
        # 'ÐžÐ¿Ñ†Ð¸Ð¸': Ð² Ð»Ð¾Ð³Ð¸ Ð¸Ð´ÑƒÑ‚ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐºÐ¾Ð´Ñ‹, Ð±ÐµÐ· Ñ€Ð°ÑÑˆÐ¸Ñ„Ñ€Ð¾Ð²ÐºÐ¸
        # 'Ð¤Ð¾Ñ‚Ð¾': Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð±ÐµÐ· Ñ„Ð¾Ñ‚Ð¾
    }

    # ÐŸÐµÑ€ÐµÐ´ÐµÐ»Ñ‹Ð²Ð°ÑŽ Ð»Ð¾Ð³Ð¸ Ð² ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ
    lines = logs.split('\n')[:-2]  # ÐŸÐ¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ 2 ÑƒÐ±Ð¸Ñ€Ð°ÑŽ Ñ‚.Ðº. Ñ‚Ð°Ð¼ Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð¸ Ð¿ÑƒÑÑ‚Ð°Ñ ÑÑ‚Ñ€Ð¾ÐºÐ°
    logs_dict = {}
    for line in lines:
        try:
            key = line.split('"')[1]
        except IndexError:
            continue
        start = line.index(':') + 1
        end = line.index(';')
        value = []
        for v in line[start:end].split(','):
            v = v.strip()
            if v.isnumeric():
                v = int(v)
            value.append(v)

        if key in ['ÐžÐ¿Ñ†Ð¸Ð¸', 'Ð¤Ð¾Ñ‚Ð¾']:  # ÐžÐ¿Ñ†Ð¸Ð¸ Ð±ÐµÐ· Ñ€Ð°ÑÑˆÐ¸Ñ„Ñ€Ð¾Ð²ÐºÐ¸, Ð¤Ð¾Ñ‚Ð¾ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾
            logs_dict[key] = pd.Series(value, name=key)
        else:  # ÐžÑÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ðµ ÑÑ‚Ð¾ pandas dataframe Ð² Ð²Ð¸Ð´Ðµ ÐšÐ¾Ð´Ð° Ð¸ Ð Ð°ÑÑˆÐ¸Ñ„Ñ€Ð¾Ð²ÐºÐ¸
            df2 = pd.Series(value, name='ÐšÐ¾Ð´', dtype='string')
            joined = pd.merge(template, df2, left_on=lookup_cols[key][0], right_on='ÐšÐ¾Ð´')
            joined.drop_duplicates(subset=[lookup_cols[key][0]], inplace=True)
            joined = joined[[lookup_cols[key][0], lookup_cols[key][1]]]
            logs_dict[key] = joined

    file_date = str(datetime.datetime.now()).replace(' ', '_').replace(':', '-')
    logs_save_path = f'converter/{client}/logs/log_{client}_{file_date}.xlsx'
    os.makedirs(os.path.dirname(logs_save_path), exist_ok=True)

    # Ð“Ð¾Ñ‚Ð¾Ð²Ñ‹Ðµ Ð»Ð¾Ð³Ð¸ Ð² xlsx
    with pd.ExcelWriter(logs_save_path) as writer:
        for key, value in logs_dict.items():
            df = pd.DataFrame(value)
            # Ð¢Ð°ÐºÐ¾Ð¹ Ð´Ð»Ð¸Ð½Ð½Ñ‹Ð¹ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚ Ñ‡Ñ‚Ð¾Ð±Ñ‹ ÑƒÐ±Ñ€Ð°Ñ‚ÑŒ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¾Ð² ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ðµ pandas Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÑÐµÑ‚ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ
            df.T.reset_index().T.to_excel(writer, sheet_name=key, header=False, index=False)
    return logs_save_path


def bot_messages(logs, logs_xlsx, price, client_slug, client_name):
    """
    Ð¡Ð¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð´Ð»Ñ Ñ‚ÐµÐ»ÐµÐ³Ñ€Ð°Ð¼ Ð±Ð¾Ñ‚Ð°
    :param logs: Ð»Ð¾Ð³Ð¸ Ð¾Ñ‚ converter_logs
    :param logs_xlsx: Ð»Ð¾Ð³Ð¸ Ð² xlsx Ð¾Ñ‚ logs_to_xlsx
    :param price: Ð¿Ñ€Ð°Ð¹Ñ Ð¾Ñ‚ converter_process_result
    :param client_slug: ÐºÐ»Ð¸ÐµÐ½Ñ‚ ÐºÐ°Ðº client_slug Ð´Ð»Ñ Ð¸Ð¼ÐµÐ½Ð¸ Ð¿Ð°Ð¿ÐºÐ¸ Ð¸ Ñ„Ð°Ð¹Ð»Ð°
    :param client_name: ÐºÐ»Ð¸ÐµÐ½Ñ‚ ÐºÐ°Ðº client_name Ð´Ð»Ñ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð±Ð¾Ñ‚Ð°
    """
    # ÐŸÑ€Ð°Ð¹Ñ Ð² csv
    file_date = str(datetime.datetime.now()).replace(' ', '_').replace(':', '-')
    price_save_path = f'converter/{client_slug}/prices/price_{client_slug}_{file_date}.csv'
    price.to_csv(price_save_path, sep=';', header=True, encoding='cp1251', index=False, decimal=',')

    # ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð»Ð¾Ð³Ð¾Ð² Ð¸ Ð¿Ñ€Ð°Ð¹ÑÐ° Ñ‡ÐµÑ€ÐµÐ· Ð±Ð¾Ñ‚Ð° Ñ‚ÐµÐ»ÐµÐ³Ñ€Ð°Ð¼Ð°
    chat_ids = ConverterLogsBotData.objects.all()
    logs = f'ðŸŸ¢ {client_name}\n\n{logs}'
    for chat_id in chat_ids:
        if len(logs) > 4095:  # Ð£ Ñ‚ÐµÐ»ÐµÐ³Ñ€Ð°Ð¼Ð° Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ðµ Ð½Ð° 4096 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð² Ð² ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¸
            for x in range(0, len(logs), 4095):
                bot.send_message(chat_id.chat_id, logs[x:x + 4095])
        else:
            bot.send_message(chat_id.chat_id, logs)
        bot.send_document(chat_id.chat_id, InputFile(logs_xlsx))
        bot.send_document(chat_id.chat_id, InputFile(price_save_path))

    os.remove(price_save_path)
    return


def save_on_ftp(save_path):
    """
    Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ Ñ„Ð°Ð¹Ð» Ð½Ð° ftp
    :param save_path: Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ð¿ÑƒÑ‚ÑŒ Ðº Ñ„Ð°Ð¹Ð»Ñƒ
    """
    file_path = Path(save_path)
    with FTP('ph.onllline.ru', env('FTP_LOGIN'), env('FTP_PASSWORD')) as ftp, open(save_path, 'rb') as file:
        cd_tree(ftp, str(file_path.parents[0]))
        ftp.storbinary(f'STOR {file_path.name}', file)
        ftp.cwd('/')
    return


def cd_tree(ftp, path):
    """
    Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ñ‚ Ð¿Ð°Ð¿ÐºÐ¸ Ð½Ð° ftp ÐµÑÐ»Ð¸ Ð¾Ð½Ð¸ Ð½Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‚
    :param ftp: FTP ÐºÐ»Ð°ÑÑ Ð¸Ð· ftplib
    :param path: Ð¿ÑƒÑ‚ÑŒ ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð½ÑƒÐ¶ÐµÐ½ Ð½Ð° ftp
    """
    path = path.replace('\\', '/')  # ÐšÐ¾ÑÑ‚Ñ‹Ð»ÑŒ Ð´Ð»Ñ windows
    for folder in path.split('/'):
        try:
            ftp.cwd(folder)
        except ftplib.error_perm:
            ftp.mkd(folder)
            ftp.cwd(folder)
    return


def get_photo_folders():
    """ ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ Ð¾Ñ‚ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚ÐµÑ€Ð° ÑÐ¿Ð¸ÑÐ¾Ðº Ð¿Ð°Ð¿Ð¾Ðº Ñ Ñ„Ð¾Ñ‚Ð¾ Ð¸ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÑ‚ Ð½Ð¾Ð²Ñ‹Ðµ Ð² Ð±Ð°Ð·Ñƒ """
    url = 'http://151.248.118.19/Api/Stock/GetClients'
    response = requests.post(url).json()
    current_folders = [f.folder for f in PhotoFolder.objects.all()]
    new_folders = []
    for folder in response:
        if folder not in current_folders:
            new_folders.append(PhotoFolder(folder=folder))
    PhotoFolder.objects.bulk_create(new_folders)
    return


def get_configurations():
    """ ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ Ð¾Ñ‚ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚ÐµÑ€Ð° ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸ Ð¸ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÑ‚/Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÐµÑ‚ Ð² Ð±Ð°Ð·Ðµ """
    url = 'http://151.248.118.19/Api/Configurations/GetList'
    response = requests.post(url).json()
    current_configurations = Configuration.objects.all()
    new_configurations = []
    updated_configurations = []
    for conf in response:
        exists = current_configurations.filter(converter_id=conf['id'])
        if exists.count() > 0:
            updated = exists[0]
            updated.name = conf['name']
            updated.configuration = conf['configuration']
            updated_configurations.append(updated)
        else:
            new_configurations.append(Configuration(converter_id=conf['id'], name=conf['name'],
                                                    configuration=conf['configuration']))
    Configuration.objects.bulk_update(updated_configurations, ['name', 'configuration'])
    if len(new_configurations):
        Configuration.objects.bulk_create(new_configurations)
    return
