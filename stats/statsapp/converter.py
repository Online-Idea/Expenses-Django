import ftplib
from ftplib import FTP
from pathlib import Path
import os
import requests
import datetime
import xml.etree.ElementTree as ET
import xlsxwriter
import pandas as pd
from telebot.types import InputFile

from stats.settings import env
from statsapp.models import *
from statsapp.management.commands.bot import bot


# –°–ø–∏—Å–æ–∫ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π: POST http://151.248.118.19/Api/Configurations/GetList
# –°–ø–∏—Å–æ–∫ –ü–∞–ø–æ–∫ —Å —Ñ–æ—Ç–æ: POST http://151.248.118.19/Api/Stock/GetClients

# –ü—Ä–æ–≥–æ–Ω —à–∞–±–ª–æ–Ω–∞ (4 –∑–∞–ø—Ä–æ—Å–∞)
# POST http://151.248.118.19/Api/Stock/StartProcess
# POST http://151.248.118.19/Api/Stock/GetProcessStep
# POST http://151.248.118.19/Api/Stock/GetProcessResult
# POST http://151.248.118.19/Api/Log/GetByProcessId

def get_converter_tasks():
    active_tasks = ConverterTask.objects.filter(active=True)
    return active_tasks


def get_price(task):
    """
    –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –¥–ª—è –æ–¥–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞.
    :param task: —Å—Ç—Ä–æ–∫–∞ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã –ó–∞–¥–∞—á–∏ –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–∞
    """
    template = converter_template(task)
    client_slug = task.client.slug
    client_name = task.client.name
    process_id = converter_post(task)
    print(f'–ö–ª–∏–µ–Ω—Ç {client_slug}, pid: {process_id}')
    progress = converter_process_step(process_id)
    while progress < 100:
        print(progress)
        progress = converter_process_step(process_id)
    price = converter_process_result(process_id, client_slug)
    logs = converter_logs(process_id)
    logs_xlsx = logs_to_xlsx(logs, template, client_slug)
    bot_messages(logs, logs_xlsx, price, client_slug, client_name)
    save_on_ftp(logs_xlsx)
    os.remove(logs_xlsx)

    print(f'–ö–ª–∏–µ–Ω—Ç {client_slug} - –ø—Ä–∞–π—Å –≥–æ—Ç–æ–≤')
    return


def converter_template(task):
    # –°–æ—Ö—Ä–∞–Ω—è—é —Å—Ç–æ–∫ –∫–ª–∏–µ–Ω—Ç–∞, –¥–µ–ª–∞—é –ø–æ –Ω–µ–º—É —à–∞–±–ª–æ–Ω –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–∞
    slug = task.client.slug
    file_date = str(datetime.datetime.now()).replace(' ', '_').replace(':', '-')
    stock_path = f'converter/{slug}/stocks/stock_{slug}_{file_date}'

    # –ü–æ–ª—É—á–∞—é —Å—Ç–æ–∫
    if task.stock_source == '–°—Å—ã–ª–∫–∞':
        response = requests.get(url=task.stock_url)
    elif task.stock_source == 'POST-–∑–∞–ø—Ä–æ—Å':
        data = {
            'login': task.stock_post_login,
            'password': task.stock_post_password,
        }
        response = requests.post(url=task.stock_post_host, data=data)

    # –ü–æ–ª—É—á–∞—é —Ç–∏–ø —Ñ–∞–π–ª–∞ —Å—Ç–æ–∫–∞
    content_type = response.headers['content-type']
    if 'text/xml' in content_type or 'application/xml' in content_type:
        stock_path += '.xml'
        content_type = 'xml'
    elif 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet' in content_type:
        stock_path += '.xlsx'
        content_type = 'xlsx'

    # –°–æ—Ö—Ä–∞–Ω—è—é —Å—Ç–æ–∫ –Ω–∞ ftp
    os.makedirs(os.path.dirname(stock_path), mode=0o755, exist_ok=True)
    with open(stock_path, mode='wb') as file:
        file.write(response.content)
    # with open(stock_path, mode='w', encoding=task.stock_fields.encoding) as file:
    #     file.write(response.text)
    save_on_ftp(stock_path)

    # –ü—É—Ç—å —à–∞–±–ª–æ–Ω–∞
    template_path = f'converter/{slug}/templates/template_{slug}_{file_date}.xlsx'
    os.makedirs(os.path.dirname(template_path), exist_ok=True)
    task.template = template_path
    task.save()

    # –†–∞–∑–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞ —Å—Ç–æ–∫–∞
    if content_type == 'xml':
        template = template_xml(stock_path, template_path, task)
    elif content_type == 'xlsx':
        template = template_xlsx(stock_path, template_path, task)

    save_on_ftp(template_path)
    os.remove(stock_path)

    return template


def template_xml(stock_path, template_path, task):
    # XML tree
    tree = ET.parse(stock_path)
    root = tree.getroot()

    # XLSX —à–∞–±–ª–æ–Ω
    xlsx_template = xlsxwriter.Workbook(template_path)
    sheet = xlsx_template.add_worksheet('–®–∞–±–ª–æ–Ω')

    # –ó–∞–≥–æ–ª–æ–≤–∫–∏ —à–∞–±–ª–æ–Ω–∞
    template_col = StockFields.TEMPLATE_COL
    for k, col in template_col.items():
        sheet.write(0, col[1], col[0])

    # –î–∞–Ω–Ω—ã–µ —à–∞–±–ª–æ–Ω–∞
    fields = task.stock_fields
    exception_col = ['modification_code', 'options_code', 'images', 'modification_explained']
    for i, car in enumerate(root.iter(fields.car_tag)):
        # sheet.write(y, x, cell_data)  # –ü—Ä–∏–º–µ—Ä –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è —è—á–µ–π–∫–∏ xlsx
        if stock_xml_filter(car, task):
            # –û–±—ã—á–Ω—ã–µ –ø–æ–ª—è
            for field in fields._meta.fields:
                field_val = getattr(fields, field.name)
                # –ï—Å–ª–∏ –Ω–µ –ø—É—Å—Ç–æ –ò –ø–æ–ª–µ –≤ –ø–æ–ª—è—Ö —à–∞–±–ª–æ–Ω–∞ –ò –ø–æ–ª–µ –ù–ï –≤ –∏—Å–∫–ª—é—á–µ–Ω–∏—è—Ö
                if field_val and field.name in template_col and field.name not in exception_col:
                    cell = car.findtext(field_val)
                    try:
                        if cell.isnumeric():
                            cell = int(cell)
                    except AttributeError:
                        pass
                    sheet.write(i + 1, template_col[field.name][1], cell)

            # –ü–æ–ª—è-–∏—Å–∫–ª—é—á–µ–Ω–∏—è
            if ',' in fields.modification_code:  # –ö–æ–¥ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏
                # –†–∞–∑–¥–µ–ª—è–µ—Ç –ø–æ –∑–∞–ø—è—Ç–æ–π –≤ —Å–ø–∏—Å–æ–∫ –µ—Å–ª–∏ –µ—Å—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ. –£–±–∏—Ä–∞–µ—Ç –∑–∞–ø—è—Ç—É—é –∏–∑ –¥–∞–Ω–Ω—ã—Ö —Å—Ç–æ–∫–∞
                mod = [car.findtext(f).replace(',', '') for f in fields.modification_code.split(', ') if car.findtext(f)]
                sheet.write(i + 1, template_col['modification_code'][1], ' | '.join(mod))
            else:
                sheet.write(i + 1, template_col['modification_code'][1], car.findtext(fields.modification_code))

            if fields.options_code:
                options = multi_tags(fields.options_code, car)  # –û–ø—Ü–∏–∏
                sheet.write(i + 1, template_col['options_code'][1], options)

            if fields.images:
                images = multi_tags(fields.images, car)  # –§–æ—Ç–æ –∫–ª–∏–µ–Ω—Ç–∞
                sheet.write_string(i + 1, template_col['images'][1], images)

            if ',' in fields.modification_explained:  # –†–∞—Å—à. –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏
                mod = [car.findtext(f) for f in fields.modification_explained.split(', ') if car.findtext(f)]
                sheet.write(i + 1, template_col['modification_explained'][1], ' | '.join(mod))
            else:
                sheet.write(i + 1, template_col['modification_explained'][1], car.findtext(fields.modification_explained))

    xlsx_template.close()

    return pd.read_excel(template_path, decimal=',')


# TODO –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ f.value. –ü–æ—Ç–æ–º –¥–ª—è xlsx —Å—Ç–æ–∫–æ–≤
def stock_xml_filter(car, task):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∞–≤—Ç–æ–º–æ–±–∏–ª—å –∏–∑ xml —Å—Ç–æ–∫–∞ –ø–æ —Ñ–∏–ª—å—Ç—Ä–∞–º –∏–∑ ConverterFilters
    :param car: node –∞–≤—Ç–æ–º–æ–±–∏–ª—è –∏–∑ xml —Å—Ç–æ–∫–∞
    :param task: task (–∑–∞–ø–∏—Å—å) –∏–∑ —Ç–∞–±–ª–∏—Ü—ã –ó–∞–¥–∞—á–∏ –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–∞
    :return: True –µ—Å–ª–∏ —Ñ–∏–ª—å—Ç—Ä—ã –ø—Ä–æ–π–¥–µ–Ω—ã
    """
    filters = ConverterFilters.objects.filter(converter_task=task)
    dict_filters, stock_fields, result = [], [], []

    # –ü–µ—Ä–µ–≤–æ–∂—É —Ñ–∏–ª—å—Ç—Ä—ã –≤ —Å–ª–æ–≤–∞—Ä—å –≤–∏–¥–∞: {'values': values, 'condition': condition, 'field': field}
    for f in filters:
        # –ó–Ω–∞—á–µ–Ω–∏—è
        if '`' in f.value:
            values = [val.replace('`', '').strip() for val in f.value.split('`,')]
        else:
            values = [f.value]

        # –ü–æ–ª—è (—Ç–µ–≥–∏)
        if '/' in f.field:  # –ü—É—Ç—å –∫ –¥–µ—Ç—è–º
            parent = f.field.split('/')[0]

            if '@' not in f.field:  # –î–µ—Ç–∏
                stock_fields = [tag.text for tag in car.find(parent)]

            else:  # –ê—Ç—Ä–∏–±—É—Ç—ã
                attribute_name = f.field.split('@')[1].split('=')[0]
                attribute_value = f.field.split('"')[1].replace('"', '')
                for tag in car.find(parent):
                    for tag_attribute in tag.attrib.items():
                        if tag_attribute == (attribute_name, attribute_value):
                            stock_fields = [tag.text]

        else:  # –ü—Ä–æ—Å—Ç–æ –æ–¥–∏–Ω —Ç–µ–≥
            stock_fields = [car.findtext(f.field)]

        for field in stock_fields:
            dict_filters.append({
                'values': values,
                'condition': f.condition,
                'field': field,
            })

    for sf in dict_filters:
        for value in sf['values']:
            result.append(xml_filter_conditions(value, sf['condition'], sf['field']))

    # –ï—Å–ª–∏ –¥–ª–∏–Ω–∞ —Ñ–∏–ª—å—Ç—Ä–æ–≤ —Ä–∞–≤–Ω–∞ —Å—É–º–º–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∑–Ω–∞—á–∏—Ç –∫–∞–∂–¥—ã–π —Ñ–∏–ª—å—Ç—Ä –≤–µ—Ä–Ω—É–ª True, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—å –ø–æ–¥—Ö–æ–¥–∏—Ç
    return len(dict_filters) == sum(result)


def xml_filter_conditions(value, condition, stock_field):
    """
    –£—Å–ª–æ–≤–∏—è —Ñ–∏–ª—å—Ç—Ä–∞
    :param value: –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
    :param condition: —É—Å–ª–æ–≤–∏–µ
    :param stock_field: –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ —Å—Ç–æ–∫–∞
    :return: True –µ—Å–ª–∏ —É—Å–ª–æ–≤–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ
    """
    if 'with' not in condition:
        return eval(f'"{value}" {condition} "{stock_field}"')
    elif condition == ConverterFilters.STARTS_WITH:
        return stock_field.startswith(value)
    elif condition == ConverterFilters.NOT_STARTS_WITH:
        return not(stock_field.startswith(value))
    elif condition == ConverterFilters.ENDS_WITH:
        return stock_field.endswith(value)
    elif condition == ConverterFilters.NOT_ENDS_WITH:
        return not(stock_field.endswith(value))


def template_xlsx(stock_path, template_path, task):
    df_stock = pd.read_excel(stock_path, decimal=',')
    df_stock = stock_xlsx_filter(df_stock, task)

    fields = StockFields.objects.filter(pk=task.stock_fields.id)
    fields = fields.values()[0]
    template_col = StockFields.TEMPLATE_COL

    # –ú–µ–Ω—è—é –∏–º–µ–Ω–∞ —Å—Ç–æ–ª–±—Ü–æ–≤
    swapped_cols = {v: template_col[k][0] for k, v in fields.items() if k in template_col}
    df_stock.rename(columns=swapped_cols, inplace=True)

    # –î–æ–±–∞–≤–ª—è—é –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Å—Ç–æ–ª–±—Ü—ã
    cur_cols = list(df_stock.columns.values)
    for k, col in template_col.items():
        if col[0] not in cur_cols:
            df_stock[col[0]] = ''

    # –û—Å—Ç–∞–≤–ª—è—é —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –≤ —Ç–æ–º –ø–æ—Ä—è–¥–∫–µ –∫–∞–∫ –≤ template_col
    df_stock = df_stock[[v[0] for k, v in template_col.items()]]
    # –í –û–ø—Ü–∏–∏ –∏ –ø–∞–∫–µ—Ç—ã –∑–∞–º–µ–Ω—è—é –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –Ω–∞ –ø—Ä–æ–±–µ–ª
    df_stock['–û–ø—Ü–∏–∏ –∏ –ø–∞–∫–µ—Ç—ã'].replace(r'\n', ' ', regex=True, inplace=True)

    df_stock.T.reset_index().T.to_excel(template_path, sheet_name='–®–∞–±–ª–æ–Ω', header=False, index=False)

    return df_stock


def stock_xlsx_filter(df, task):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∞–≤—Ç–æ–º–æ–±–∏–ª—å –∏–∑ xlsx —Å—Ç–æ–∫–∞ –ø–æ —Ñ–∏–ª—å—Ç—Ä–∞–º –∏–∑ ConverterFilters
    :param df: xlsx —Å—Ç–æ–∫ –≤ –≤–∏–¥–µ pandas dataframe
    :param task: task (–∑–∞–ø–∏—Å—å) –∏–∑ —Ç–∞–±–ª–∏—Ü—ã –ó–∞–¥–∞—á–∏ –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–∞
    :return: –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π dataframe
    """
    filters = ConverterFilters.objects.filter(converter_task=task)
    filter_strings = []
    for f in filters:
        if '`' in f.value:
            values = [val.replace('`', '').strip() for val in f.value.split('`,')]
        else:
            values = [f.value]

        # TODO –¥–ª—è —É—Å–ª–æ–≤–∏–π —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –Ω—É–∂–Ω–æ –ø–∏—Å–∞—Ç—å –ò–õ–ò —á–µ—Ä–µ–∑ |
        # –¢.–µ. –≤–º–µ—Å—Ç–æ df.loc[(df["VIN"].str.startswith("Z9M2130055L045585")) & (df["VIN"].str.startswith("Z9M2130055L046037")) & (df["–ú–æ–¥–µ–ª—å"] == "E (W/S213)")]
        # –ü–∏—Å–∞—Ç—å df.loc[(df["VIN"].str.startswith("Z9M2130055L045585")) | (df["VIN"].str.startswith("Z9M2130055L046037")) & (df["–ú–æ–¥–µ–ª—å"] == "E (W/S213)")]
        for value in values:
            if f.condition == ConverterFilters.CONTAINS:
                filter_strings.append(f'(df["{f.field}"].str.contains({value})')
            elif f.condition == ConverterFilters.NOT_CONTAINS:
                filter_strings.append(f'(~df["{f.field}"].str.contains({value})')
            elif f.condition == ConverterFilters.EQUALS:
                filter_strings.append(f'(df["{f.field}"] == "{value}")')
            elif f.condition == ConverterFilters.NOT_EQUALS:
                filter_strings.append(f'(~df["{f.field}"] == "{value}")')
            elif f.condition == ConverterFilters.STARTS_WITH:
                filter_strings.append(f'(df["{f.field}"].str.startswith("{value}"))')
            elif f.condition == ConverterFilters.NOT_STARTS_WITH:
                filter_strings.append(f'~(df["{f.field}"].str.startswith("{value}"))')
            elif f.condition == ConverterFilters.ENDS_WITH:
                filter_strings.append(f'(df["{f.field}"].str.endswith("{value}")')
            elif f.condition == ConverterFilters.NOT_ENDS_WITH:
                filter_strings.append(f'~(df["{f.field}"].str.endswith("{value}")')
        print(f'df.loc[{" & ".join(filter_strings)}]')

    return eval(f'df.loc[{" & ".join(filter_strings)}]')


def multi_tags(field, element):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–æ–ª—è –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –¥–∞–Ω–Ω—ã–µ —Å–æ–±–∏—Ä–∞—é—Ç—Å—è –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–µ–≥–æ–≤
    :param field: –ø–æ–ª–µ
    :param element: —ç–ª–µ–º–µ–Ω—Ç –∏–∑ xml
    :return: –≥–æ—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —à–∞–±–ª–æ–Ω–∞
    """
    if '/' in field:
        parent = field.split('/')[0]
        if '@' not in field:  # –ï—Å–ª–∏ —Ç–µ–≥ —Å –¥–µ—Ç—å–º–∏ –∏ –Ω—É–∂–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–µ—Ç–µ–π
            result = [tag.text for tag in element.find(parent)]
        else:  # –ï—Å–ª–∏ —Ç–µ–≥ —Å –¥–µ—Ç—å–º–∏ –∏ –∏–∑ –¥–µ—Ç–µ–π –Ω—É–∂–µ–Ω –∞—Ç—Ä–∏–±—É—Ç
            attribute = field.split('@')[1]
            result = [tag.attrib[attribute] for tag in element.find(parent)]
    else:
        if '@' not in field:  # –ï—Å–ª–∏ —Ç–µ–≥ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –ø–æ–≤—Ç–æ—Ä—è–µ—Ç—Å—è –∏ –Ω—É–∂–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ
            result = [tag.text for tag in element.findall(field)]
        else:  # –ï—Å–ª–∏ —Ç–µ–≥ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –ø–æ–≤—Ç–æ—Ä—è–µ—Ç—Å—è –∏ –∏–∑ –Ω–µ–≥–æ –Ω—É–∂–µ–Ω –∞—Ç—Ä–∏–±—É—Ç
            tag_name, attribute = field.split('@')
            result = [tag.attrib[attribute] for tag in element.findall(tag_name)]

    return ' '.join(result)


def converter_post(task):
    """
    –ü–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å –∫ –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä—É. –û—Ç–ø—Ä–∞–≤–ª—è—é—Ç—Å—è –æ–ø—Ü–∏–∏ –∏ —Ñ–∞–π–ª —à–∞–±–ª–æ–Ω–∞.
    :param task: task (–∑–∞–ø–∏—Å—å) –∏–∑ —Ç–∞–±–ª–∏—Ü—ã –ó–∞–¥–∞—á–∏ –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–∞
    :return: process_id –¥–ª—è converter_process_step –∏ converter_process_result
    """
    url = 'http://151.248.118.19/Api/Stock/StartProcess'

    configuration = task.configuration.configuration if task.configuration is not None else Configuration.DEFAULT
    payload = {
        'client': task.photos_folder.folder,
        'configuration': configuration,
        'frontLength': task.front,
        'backLength': task.back,
        'interiorsLength': task.interior,
        'onlySalon': task.salon_only,
    }
    template = open(task.template, 'rb')
    files = {'file': ('template.xlsx', template, 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                      {'Expires': '0'})}
    response = requests.post(url=url, data=payload, files=files)
    process_id = response.json()['processId']
    template.close()
    os.remove(task.template)
    return process_id


def converter_process_step(process_id):
    """
    –í—Ç–æ—Ä–æ–π –∑–∞–ø—Ä–æ—Å, –∫–æ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç progress:100 –∑–Ω–∞—á–∏—Ç –ø—Ä–∞–π—Å –≥–æ—Ç–æ–≤, –º–æ–∂–Ω–æ –≤—ã–∑—ã–≤–∞—Ç—å converter_process_result
    :param process_id: –∏–∑ converter_post
    """
    url = 'http://151.248.118.19/Api/Stock/GetProcessStep'
    payload = {'processId': process_id}
    response = requests.post(url=url, json=payload)
    progress = response.json()['progress']
    return progress


def converter_process_result(process_id, client):
    """
    –¢—Ä–µ—Ç–∏–π –∑–∞–ø—Ä–æ—Å, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–æ—Ç–æ–≤—ã–π –ø—Ä–∞–π—Å
    :param process_id: –∏–∑ converter_post
    :param client: –∏–º—è –∫–ª–∏–µ–Ω—Ç–∞ –∫–∞–∫ slug - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ –∏–º—è –ø–∞–ø–∫–∏ –∫–ª–∏–µ–Ω—Ç–∞ –∫—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –ø—Ä–∞–π—Å
    """
    url = 'http://151.248.118.19/Api/Stock/GetProcessResult'
    payload = {'processId': (None, process_id)}
    response = requests.post(url=url, files=payload)
    file_date = str(datetime.datetime.now()).replace(' ', '_').replace(':', '-')
    save_path_date = f'converter/{client}/prices/price_{client}_{file_date}.xlsx'
    os.makedirs(os.path.dirname(save_path_date), exist_ok=True)
    with open(save_path_date, 'wb') as file:
        file.write(response.content)
    save_on_ftp(save_path_date)
    save_path = f'converter/{client}/prices/price_{client}.csv'
    read_file = pd.read_excel(save_path_date, decimal=',')
    # –£–±–∏—Ä–∞—é –∞–≤—Ç–æ–º–æ–±–∏–ª–∏ –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∞–Ω—ã (–ø—É—Å—Ç—ã–µ —Å—Ç–æ–ª–±—Ü—ã –ú–∞—Ä–∫–∞, –¶–≤–µ—Ç –ª–∏–±–æ –§–æ—Ç–æ)
    read_file = read_file[(~read_file['–ú–∞—Ä–∫–∞'].isnull()) &
                          (~read_file['–¶–≤–µ—Ç'].isnull()) &
                          (~read_file['–§–æ—Ç–æ'].isnull())]
    read_file.fillna('', inplace=True)
    read_file = read_file.astype(str).replace(r'\.0$', '', regex=True)
    read_file.to_csv(save_path, sep=';', header=True, encoding='cp1251', index=False, decimal=',')
    save_on_ftp(save_path)
    os.remove(save_path_date)
    os.remove(save_path)
    return read_file


def converter_logs(process_id):
    """
    –õ–æ–≥–∏ –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–∞
    :param process_id: –∏–∑ converter_post
    """
    # –õ–æ–≥–∏ –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏—Å—ã–ª–∞–µ—Ç –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä
    url = 'http://151.248.118.19/Api/Log/GetByProcessId'
    payload = {'processId': process_id}
    response = requests.post(url=url, json=payload)
    logs = response.json()['log']
    return logs


def logs_to_xlsx(logs, template, client):
    """
    –õ–æ–≥–∏ –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–∞ –≤–º–µ—Å—Ç–µ —Å —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–æ–π –≤ xlsx
    :param logs: –ª–æ–≥–∏ –æ—Ç converter_logs
    :param template: —à–∞–±–ª–æ–Ω –æ—Ç converter_template
    :param client: –∫–ª–∏–µ–Ω—Ç –∫–∞–∫ client_slug –¥–ª—è –∏–º–µ–Ω–∏ –ø–∞–ø–∫–∏ –∏ —Ñ–∞–π–ª–∞
    :return: xlsx —Ñ–∞–π–ª –ª–æ–≥–æ–≤
    """
    lookup_cols = {
        # –ë–∞–∑–∞ –∏–∑ –ª–æ–≥–∞: (–ò–º—è —Å—Ç–æ–ª–±—Ü–∞ —Å –∫–æ–¥–æ–º, –ò–º—è —Å—Ç–æ–ª–±—Ü–∞ —Å —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–æ–π)
        '–ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏': ('–ö–æ–¥ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏', '–†–∞—Å—à. –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏'),
        '–¶–≤–µ—Ç–∞': ('–ö–æ–¥ —Ü–≤–µ—Ç–∞', '–†–∞—Å—à. —Ü–≤–µ—Ç–∞'),
        '–ò–Ω—Ç–µ—Ä—å–µ—Ä—ã': ('–ö–æ–¥ –∏–Ω—Ç–µ—Ä—å–µ—Ä–∞', '–†–∞—Å—à. –∏–Ω—Ç–µ—Ä—å–µ—Ä–∞'),
        '–ö–æ–º–ø–ª–µ–∫—Ç–∞—Ü–∏–∏': ('–ö–æ–¥ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏', '–†–∞—Å—à. –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏'),
        # '–û–ø—Ü–∏–∏': –≤ –ª–æ–≥–∏ –∏–¥—É—Ç —Ç–æ–ª—å–∫–æ –∫–æ–¥—ã, –±–µ–∑ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏
        # '–§–æ—Ç–æ': —Ç–æ–ª—å–∫–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–µ–∑ —Ñ–æ—Ç–æ
    }

    # –ü–µ—Ä–µ–¥–µ–ª—ã–≤–∞—é –ª–æ–≥–∏ –≤ —Å–ª–æ–≤–∞—Ä—å
    lines = logs.split('\n')[:-1]
    logs_dict = {}
    for line in lines:
        key = line.split('"')[1]
        start = line.index(':') + 1
        end = line.index(';')
        value = []
        for v in line[start:end].split(','):
            v = v.strip()
            if v.isnumeric():
                v = int(v)
            value.append(v)

        if key in ['–û–ø—Ü–∏–∏', '–§–æ—Ç–æ']:  # –û–ø—Ü–∏–∏ –±–µ–∑ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏, –§–æ—Ç–æ —Ç–æ–ª—å–∫–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
            logs_dict[key] = pd.Series(value, name=key)
        else:  # –û—Å—Ç–∞–ª—å–Ω—ã–µ —ç—Ç–æ pandas dataframe –≤ –≤–∏–¥–µ –ö–æ–¥–∞ –∏ –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏
            df2 = pd.Series(value, name='–ö–æ–¥', dtype='string')
            joined = pd.merge(template, df2, left_on=lookup_cols[key][0], right_on='–ö–æ–¥')
            joined.drop_duplicates(subset=[lookup_cols[key][0]], inplace=True)
            joined = joined[[lookup_cols[key][0], lookup_cols[key][1]]]
            logs_dict[key] = joined

    file_date = str(datetime.datetime.now()).replace(' ', '_').replace(':', '-')
    logs_save_path = f'converter/{client}/logs/log_{client}_{file_date}.xlsx'
    os.makedirs(os.path.dirname(logs_save_path), exist_ok=True)

    # –ì–æ—Ç–æ–≤—ã–µ –ª–æ–≥–∏ –≤ xlsx
    with pd.ExcelWriter(logs_save_path) as writer:
        for key, value in logs_dict.items():
            df = pd.DataFrame(value)
            # –¢–∞–∫–æ–π –¥–ª–∏–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç —á—Ç–æ–±—ã —É–±—Ä–∞—Ç—å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∫–æ—Ç–æ—Ä–æ–µ pandas –ø—Ä–∏–º–µ–Ω—è–µ—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            df.T.reset_index().T.to_excel(writer, sheet_name=key, header=False, index=False)
    return logs_save_path


def bot_messages(logs, logs_xlsx, price, client_slug, client_name):
    """
    –°–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è —Ç–µ–ª–µ–≥—Ä–∞–º –±–æ—Ç–∞
    :param logs: –ª–æ–≥–∏ –æ—Ç converter_logs
    :param logs_xlsx: –ª–æ–≥–∏ –≤ xlsx –æ—Ç logs_to_xlsx
    :param price: –ø—Ä–∞–π—Å –æ—Ç converter_process_result
    :param client_slug: –∫–ª–∏–µ–Ω—Ç –∫–∞–∫ client_slug –¥–ª—è –∏–º–µ–Ω–∏ –ø–∞–ø–∫–∏ –∏ —Ñ–∞–π–ª–∞
    :param client_name: –∫–ª–∏–µ–Ω—Ç –∫–∞–∫ client_name –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏—è –±–æ—Ç–∞
    """
    # –ü—Ä–∞–π—Å –≤ csv
    file_date = str(datetime.datetime.now()).replace(' ', '_').replace(':', '-')
    price_save_path = f'converter/{client_slug}/prices/price_{client_slug}_{file_date}.csv'
    price.to_csv(price_save_path, sep=';', header=True, encoding='cp1251', index=False, decimal=',')

    # –û—Ç–ø—Ä–∞–≤–∫–∞ –ª–æ–≥–æ–≤ –∏ –ø—Ä–∞–π—Å–∞ —á–µ—Ä–µ–∑ –±–æ—Ç–∞ —Ç–µ–ª–µ–≥—Ä–∞–º–∞
    chat_ids = ConverterLogsBotData.objects.all()
    for chat_id in chat_ids:
        if len(logs) > 4095:  # –£ —Ç–µ–ª–µ–≥—Ä–∞–º–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ 4096 —Å–∏–º–≤–æ–ª–æ–≤ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏
            for x in range(0, len(logs), 4095):
                bot.send_message(chat_id.chat_id, logs[x:x + 4095])
        else:
            bot.send_message(chat_id.chat_id, f'üîµ {client_name}\n\n{logs}')
        bot.send_document(chat_id.chat_id, InputFile(logs_xlsx))
        bot.send_document(chat_id.chat_id, InputFile(price_save_path))

    os.remove(price_save_path)
    return


def save_on_ftp(save_path):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ñ–∞–π–ª –Ω–∞ ftp
    :param save_path: –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
    """
    file_path = Path(save_path)
    with FTP('ph.onllline.ru', env('FTP_LOGIN'), env('FTP_PASSWORD')) as ftp, open(save_path, 'rb') as file:
        cd_tree(ftp, str(file_path.parents[0]))
        ftp.storbinary(f'STOR {file_path.name}', file)
        ftp.cwd('/')
    return


def cd_tree(ftp, path):
    """
    –°–æ–∑–¥–∞—ë—Ç –ø–∞–ø–∫–∏ –Ω–∞ ftp –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
    :param ftp: FTP –∫–ª–∞—Å—Å –∏–∑ ftplib
    :param path: –ø—É—Ç—å –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–µ–Ω –Ω–∞ ftp
    """
    path = path.replace('\\', '/')  # –ö–æ—Å—Ç—ã–ª—å –¥–ª—è windows
    for folder in path.split('/'):
        try:
            ftp.cwd(folder)
        except ftplib.error_perm:
            ftp.mkd(folder)
            ftp.cwd(folder)


def get_photo_folders():
    """ –ü–æ–ª—É—á–∞–µ—Ç –æ—Ç –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–∞ —Å–ø–∏—Å–æ–∫ –ø–∞–ø–æ–∫ —Å —Ñ–æ—Ç–æ –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–µ –≤ –±–∞–∑—É """
    url = 'http://151.248.118.19/Api/Stock/GetClients'
    response = requests.post(url).json()
    current_folders = [f.folder for f in PhotoFolder.objects.all()]
    new_folders = []
    for folder in response:
        if folder not in current_folders:
            new_folders.append(PhotoFolder(folder=folder))
    PhotoFolder.objects.bulk_create(new_folders)


def get_configurations():
    """ –ü–æ–ª—É—á–∞–µ—Ç –æ—Ç –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç/–æ–±–Ω–æ–≤–ª—è–µ—Ç –≤ –±–∞–∑–µ """
    url = 'http://151.248.118.19/Api/Configurations/GetList'
    response = requests.post(url).json()
    current_configurations = Configuration.objects.all()
    new_configurations = []
    updated_configurations = []
    for conf in response:
        exists = current_configurations.filter(converter_id=conf['id'])
        if exists.count() > 0:
            updated = exists[0]
            updated.name = conf['name']
            updated.configuration = conf['configuration']
            updated_configurations.append(updated)
        else:
            new_configurations.append(Configuration(converter_id=conf['id'], name=conf['name'],
                                                    configuration=conf['configuration']))
    Configuration.objects.bulk_update(updated_configurations, ['name', 'configuration'])
    if len(new_configurations):
        Configuration.objects.bulk_create(new_configurations)
